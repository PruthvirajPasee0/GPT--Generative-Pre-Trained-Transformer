# GPT--Generative-Pre-Trained-Transformer
This repository is a very simple base level implementation of a transformer used in "Attention is all you need"
